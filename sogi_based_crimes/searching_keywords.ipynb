{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import gzip\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases directory\n",
    "# all cases per year (this data is available upon request)\n",
    "dir_path = \"/data_out/cases_gzip/2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_cases = [join(dir_path, f) for f in listdir(dir_path)\n",
    "                   if isfile(join(dir_path, f))\n",
    "                   and f.endswith(\".json\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(compressed_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"((сексуальн)|(нетрадицион))\\w{2,5}\\s(ориентац)\",\n",
    "            \"(гомосек)\\w*\",\n",
    "            \"(лесби)\\w*\",\n",
    "            \"(бисекс)\\w*\",\n",
    "            \"(трансвест)\\w*\",\n",
    "            \"(транссекс)\\w*\",\n",
    "            \"(трансгендер)\\w*\",\n",
    "            \"(\\\\bтравести)\\w*\",\n",
    "            \"(\\\\bтрансух)\\w*\",\n",
    "            \"(транс)о?(фоб)\\w*\",\n",
    "            \"(ЛГБТ)\\+?(\\w*)\",\n",
    "            \"(мужелож)\\w*\",\n",
    "            \"(гомофоб)\\w*\",\n",
    "            \"(\\\\bсодоми)\\w*\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_keywords(keywords:list, doc:str) -> tuple:\n",
    "    '''\n",
    "    Searching for a list of keywords in a target text\n",
    "    Returns a tuple with N matches and the matches found\n",
    "    '''\n",
    "    \n",
    "    keywords_foud = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        match = re.search(keyword,doc,flags=re.IGNORECASE)\n",
    "        if match != None:\n",
    "            keywords_foud.append(match[0])\n",
    "            \n",
    "    tuple_to_return = (len(keywords_foud), keywords_foud)\n",
    "    \n",
    "    return tuple_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cases_by_keywords(keywords:list, path_to_gzip:str, path_to_save=\"\", year=\"\") -> str:\n",
    "    \n",
    "    with gzip.open(path_to_gzip) as jf:\n",
    "        data_by_region = json.loads(jf.read().decode(\"utf-8\"))\n",
    "        \n",
    "    n_cases_found = 0\n",
    "    region_code = path_to_gzip.split('/')[-1].split('_')[0]\n",
    "        \n",
    "    for website, cases in data_by_region.items():\n",
    "        k = 0\n",
    "        if cases.get(\"cases\") != None:\n",
    "            for doc in cases[\"cases\"]:\n",
    "                \n",
    "                if doc.get(\"case_text\") != None:\n",
    "                    target_text = doc[\"case_text\"]\n",
    "                else:\n",
    "                    target_text = ''\n",
    "                \n",
    "                matches = search_keywords(keywords,target_text)\n",
    "                \n",
    "                if matches[0] > 0:\n",
    "                    k += 1\n",
    "                    n_cases_found += 1\n",
    "                    # add a website\n",
    "                    # add matches\n",
    "                    doc[\"website\"] = website\n",
    "                    doc[\"keyword_mathces\"] = matches[1]\n",
    "\n",
    "                    # setting a case id\n",
    "                    if doc.get(\"case_id_uid\") != None:\n",
    "                        case_id = doc[\"case_id_uid\"]\n",
    "                    else:\n",
    "                        # N_region_code\n",
    "                        case_id = f\"{k}_{region_code}\"\n",
    "\n",
    "                    # save matching cases (as separate json files)    \n",
    "                    with open(f'{path_to_save}/{year}_{region_code}_{case_id}.json', 'w') as f:\n",
    "                        json.dump(doc,f,ensure_ascii=False)\n",
    "                        \n",
    "    return f\"{n_cases_found} cases are found in region {region_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = \"sudrf_keyword_search\"\n",
    "year = \"2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for compressed_case in compressed_cases[52:]:\n",
    "    region_code = compressed_case.split('/')[-1].split('_')[0]\n",
    "    find_cases_by_keywords(keywords,compressed_case,path_to_save,year=year)\n",
    "    print(f\"region {region_code} is completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The same procedure was applied for 2022 cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword search in Moscow cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_moscow_cases_by_keywords(keywords:list, path_to_cases:str, path_to_save=\"\", year=\"\") -> str:\n",
    "    \n",
    "    all_txt_files = [join(path_to_cases, f) for f in listdir(path_to_cases)\n",
    "             if isfile(join(path_to_cases, f))\n",
    "             and f.endswith(\".txt\")]\n",
    "        \n",
    "    n_cases_found = 0\n",
    "    \n",
    "    for f in all_txt_files:\n",
    "        \n",
    "        with open(f,'r') as txt_file:\n",
    "            case_text = txt_file.read()\n",
    "        \n",
    "        matches = search_keywords(keywords,case_text)\n",
    "                \n",
    "        if matches[0] > 0:\n",
    "            n_cases_found += 1\n",
    "            \n",
    "            # shape the resulting file\n",
    "            result = {}\n",
    "            result[\"case_text\"] = case_text\n",
    "            result[\"website\"] = f.split('/')[-1].split('_')[-2]\n",
    "            result[\"keyword_mathces\"] = matches[1]\n",
    "\n",
    "            # setting a case id\n",
    "            case_id = f.split('/')[-1].rstrip('.txt')\n",
    "\n",
    "            # save matching cases (as separate json files)\n",
    "            # region code 77 is const for Moscow \n",
    "            with open(f'{path_to_save}/{year}_77_{case_id}.json', 'w') as jf:\n",
    "                json.dump(result,jf,ensure_ascii=False)\n",
    "\n",
    "    return f\"{n_cases_found} cases are found ({year})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021\n",
    "path_to_save = 'sudrf_keyword_search'\n",
    "year = '2021'\n",
    "path_to_cases = 'msk/2021_txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_moscow_cases_by_keywords(keywords, path_to_cases, path_to_save, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a df from jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_cases = 'sudrf_keyword_search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases_with_keywords = [join(path_to_cases, f) for f in listdir(path_to_cases)\n",
    "             if isfile(join(path_to_cases, f))\n",
    "             and f.endswith(\".json\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_cases_df = pd.DataFrame(columns=['case_id','context','article_list','keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in all_cases_with_keywords:\n",
    "    \n",
    "    with open(case,'r') as jf:\n",
    "        doc = json.load(jf)\n",
    "        \n",
    "    # fields\n",
    "    if doc.get('metadata') != None:\n",
    "        all_art = []\n",
    "        for a in doc['metadata']['accused']:\n",
    "            all_art.extend(a['article'])\n",
    "        art_str = ''\n",
    "        for art in set(all_art):\n",
    "            art_str += f'{art},'\n",
    "            \n",
    "        if doc.get('case_id_uid') != None:\n",
    "            case_id = doc['case_id_uid']\n",
    "    else:\n",
    "        case_id = case.split('/')[-1].rstrip('.txt')\n",
    "        art_str = ''\n",
    "        \n",
    "    # get context window\n",
    "    contexts = []\n",
    "    for kw in doc['keyword_mathces']:\n",
    "        to_search = \"[\\w\\W]{200}\" + kw + \"[\\w\\W]{200}\"\n",
    "        context = re.search(to_search, doc['case_text'])\n",
    "        contexts.append(context[0])\n",
    "        \n",
    "    data_row = [case_id,contexts,art_str.rstrip(','),doc['keyword_mathces']]\n",
    "    kw_cases_df.loc[len(kw_cases_df)] = data_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = []\n",
    "for a in list_of_all_art:\n",
    "    matches = re.findall('(ст.\\s?\\d{2,3})',a)\n",
    "    all_articles.extend(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_art = Counter(all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_art.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_kws = list(kw_cases_df['keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kw = []\n",
    "for kws in list_of_all_kws:\n",
    "    for k in kws:\n",
    "        all_kw.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(all_kw).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_cases_df.to_csv('keyword_search_context_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to view the case text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_text(case_id:str) -> str:\n",
    "    \n",
    "    dir_path = \"/Users/Macintosh/Library/Mobile Documents/com~apple~CloudDocs/data_out/sudrf_keyword_search\"\n",
    "    all_cases_with_keywords = [join(dir_path, f) for f in listdir(dir_path)\n",
    "             if isfile(join(dir_path, f))\n",
    "             and f.endswith(\".json\")]\n",
    "    \n",
    "    for case_file_name in all_cases_with_keywords:\n",
    "        if case_id in case_file_name:\n",
    "            with open(case_file_name,'r') as jf:\n",
    "                doc = json.load(jf)\n",
    "                \n",
    "    return doc[\"case_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
